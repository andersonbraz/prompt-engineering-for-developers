# TRANSFORMING

Modelos de linguagem de larga escala são muito bons em transformar uma entrada em um formato diferente. Por exemplo, ao inserir um texto em um idioma, eles podem traduzi-lo para outro idioma. Ou ainda podem ajudar com correções de ortografia e gramática.

Também é possível inserir um texto com erros gramaticais e obter uma versão corrigida. E eles podem até transformar formatos, como receber HTML como entrada e gerar JSON como saída. Existem várias aplicações que eu costumava programar de forma bem trabalhosa com expressões regulares, que agora são muito mais simples de implementar com um modelo de linguagem e alguns prompts.

Eu uso o ChatGPT para revisar praticamente tudo o que escrevo hoje em dia, então estou empolgado para mostrar mais alguns exemplos no notebook agora. Primeiro, vamos importar o OpenAI e usar a mesma função auxiliar get_completion que temos usado ao longo dos vídeos. E a primeira coisa que vamos fazer é uma tarefa de tradução.

Modelos de linguagem são treinados com uma enorme variedade de textos, vindos de muitas fontes — boa parte deles da internet — e em muitos idiomas. Isso faz com que esses modelos adquiram a capacidade de traduzir.

Eles conhecem centenas de idiomas, em diferentes níveis de proficiência. Vamos passar por alguns exemplos de como usar essa habilidade.

Vamos começar com algo simples.

Neste primeiro exemplo, o prompt é: "Traduza o seguinte texto do inglês para o espanhol." Texto: "Hi, I would like to order a blender." A resposta foi: "Hola, me gustaría ordenar una licuadora." E peço desculpas aos falantes de espanhol — infelizmente nunca aprendi espanhol, como dá para perceber.

Vamos tentar outro exemplo. Nesse caso, o prompt é: "Me diga qual idioma é esse." Texto: "Combien coûte le lampadaire" (em francês). Ao rodar, o modelo identifica corretamente: "Este é francês."

O modelo também consegue fazer múltiplas traduções ao mesmo tempo.

Neste exemplo, vamos pedir para traduzir o seguinte texto para francês e espanhol. E sabe de uma coisa? Vamos adicionar também inglês estilo pirata.

Texto: "I want to order a basketball." Então temos traduções em francês, espanhol e inglês pirata.

Em alguns idiomas, a tradução muda dependendo da relação entre quem fala e quem ouve. Você pode explicar isso ao modelo de linguagem, e ele conseguirá ajustar a tradução de acordo.

Por exemplo, aqui pedimos: "Traduza o seguinte texto para o espanhol nas formas formal e informal." Texto: "Would you like to order a pillow?" Repare também que estamos usando um delimitador diferente dos tradicionais backticks. Não importa muito — o que importa é ter uma separação clara.

E agora temos as versões formal e informal da frase traduzida.

Formalidade é usada quando você fala com alguém que talvez seja mais sênior que você ou está em uma situação profissional. É aí que se usa um tom formal. Já o tom informal é quando se está conversando com um grupo de amigos, por exemplo. Eu, pessoalmente, não falo espanhol, mas meu pai fala — e ele disse que está correto.

No próximo exemplo, vamos imaginar que estamos no comando de uma empresa multinacional de e-commerce, e as mensagens dos usuários estarão em vários idiomas diferentes. Eles vão nos contar sobre problemas de TI em uma grande variedade de línguas. Então, precisamos de um tradutor universal.

Primeiro, vamos colar uma lista de mensagens de usuários em vários idiomas.

Agora vamos fazer um loop por cada uma dessas mensagens.

Por exemplo: for issue in user_messages

Em seguida, vou copiar um bloco de código um pouco mais longo.

A primeira coisa que faremos é pedir ao modelo para identificar em qual idioma está cada mensagem. Aqui está o prompt. Depois vamos imprimir o idioma da mensagem original e o conteúdo da questão. E então pediremos ao modelo para traduzir o conteúdo para inglês e coreano.

Executando isso...

A mensagem original está em francês.

Temos uma variedade de idiomas, e o modelo traduz cada um deles para inglês e coreano.

Você pode ver que o modelo diz: “Este é francês”. Isso porque a resposta para esse prompt será: “Este é francês”. Se quiser que seja apenas uma palavra, pode editar o prompt pedindo: “Diga qual idioma é este, responda com uma única palavra”, ou algo como “não use uma frase completa”. Também poderia pedir a resposta em formato JSON — isso provavelmente ajudaria a evitar que ele respondesse com uma sentença inteira.

E olha só — você acabou de construir um tradutor universal! Fique à vontade para pausar o vídeo e adicionar outros idiomas que quiser testar. Talvez idiomas que você mesmo fale, e ver como o modelo se sai.

A próxima coisa que vamos explorar é a transformação de tom. A escrita muda dependendo do público-alvo. A forma como eu escreveria um e-mail para um colega ou professor é obviamente bem diferente da forma como eu mando uma mensagem de texto para meu irmão mais novo. E o ChatGPT também pode ajudar a produzir diferentes estilos de escrita.

Vamos ver alguns exemplos. No primeiro, o prompt é: “Traduza o seguinte do estilo informal para uma carta comercial”. Texto: “Cara, aqui é o Joe, dá uma olhada nessa especificação da luminária.”

Vamos executar isso.

E como você pode ver, temos uma carta comercial muito mais formal com uma proposta detalhada da especificação da luminária.

Agora vamos converter entre diferentes formatos. O ChatGPT é muito bom em traduzir entre formatos como JSON para HTML, ou para XML, Markdown… todo tipo de coisa.

No prompt, descrevemos tanto o formato de entrada quanto o formato de saída. Aqui vai um exemplo: Temos um JSON que contém uma lista de funcionários de um restaurante com nome e e-mail.

No prompt, pedimos para o modelo traduzir isso de JSON para uma tabela HTML com título e cabeçalhos de coluna.

E então obtemos a resposta do modelo e a imprimimos.

Aqui temos um código HTML exibindo os nomes e e-mails de todos os funcionários.

Agora vamos ver se conseguimos visualizar esse HTML. Usaremos a função display da biblioteca Python: display(HTML(response))

Como você pode ver, isso gera uma tabela HTML corretamente formatada.

A próxima tarefa de transformação é verificação ortográfica e gramatical. Esse é um uso muito popular do ChatGPT — eu recomendo fortemente, uso o tempo todo. É especialmente útil quando se trabalha em um idioma que não é o nativo.

Aqui estão alguns exemplos de erros comuns de gramática e ortografia, e como o modelo pode ajudar a corrigi-los.

Vou colar uma lista de frases com alguns erros gramaticais ou de escrita.

Depois, vamos percorrer cada uma dessas frases e pedir ao modelo que revise e corrija.

Prompt: “Proofread and correct.” Depois usamos delimitadores.

Obtemos a resposta e a imprimimos como de costume.

O modelo consegue corrigir todos os erros gramaticais dessas frases.

Podemos usar algumas técnicas que já discutimos. Por exemplo, para melhorar o prompt, podemos dizer: “Revise e corrija o texto a seguir.” E pedir para reescrever...

Reescrever tudo...

Reescrever...

Versão corrigida. Se não encontrar nenhum erro, apenas diga: “Nenhum erro encontrado.”

Vamos tentar isso.

Dessa forma conseguimos — ah, ainda estão usando aspas aqui — mas você pode imaginar que é possível encontrar uma forma com um pouco de desenvolvimento iterativo do prompt para que funcione com mais confiabilidade.

Agora vamos fazer outro exemplo. É sempre útil revisar o texto antes de publicá-lo em fóruns públicos. Vamos usar como exemplo a análise de um panda de pelúcia.

Vamos pedir ao modelo que revise e corrija a análise.

Ótimo! Temos a versão corrigida.

Uma coisa interessante que podemos fazer é comparar a versão original da análise com a versão gerada pelo modelo. Usaremos o pacote Python redlines para isso. Vamos comparar o texto original da análise com o resultado do modelo e exibir essa diferença.

Aqui você pode ver a comparação entre o texto original e o resultado do modelo, com as correções aplicadas.

O prompt usado foi: “Revise e corrija esta análise.” Mas também é possível fazer mudanças mais profundas, como mudanças de tom, e esse tipo de coisa.

Vamos testar mais uma coisa. Neste prompt, vamos pedir ao modelo que revise e corrija a mesma análise, mas que também a torne mais atrativa, garantindo que siga o estilo APA e seja voltada para leitores avançados.

Também pediremos a saída em formato Markdown.

Estamos usando o mesmo texto da análise original acima. Executando…

E aqui temos uma versão expandida da análise do panda de pelúcia no estilo APA.

Isso conclui o vídeo sobre transformações. A seguir, temos “Expansão”, onde pegaremos um prompt curto e geraremos uma resposta mais longa e livre com o modelo de linguagem.
