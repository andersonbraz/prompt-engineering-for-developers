# INFERRING

Este próximo vídeo é sobre inferência. Gosto de pensar nessas tarefas como aquelas em que o modelo recebe um texto como entrada e realiza algum tipo de análise. Pode ser extrair rótulos, nomes, entender o sentimento do texto — esse tipo de coisa.

Então, se você quiser extrair o sentimento, positivo ou negativo, de um trecho de texto, no fluxo tradicional de aprendizado de máquina, seria necessário coletar um conjunto de dados rotulado, treinar um modelo, descobrir como implantá-lo em algum lugar na nuvem e realizar inferências. Isso até funciona bem, mas dá bastante trabalho seguir todo esse processo. E ainda, para cada tarefa — como sentimento versus extração de nomes versus outra coisa — você teria que treinar e implantar um modelo diferente.

Uma das grandes vantagens dos modelos de linguagem de larga escala é que, para muitas dessas tarefas, você pode simplesmente escrever um prompt e já começar a obter resultados praticamente de imediato. Isso oferece uma agilidade enorme no desenvolvimento de aplicações. E também é possível usar um único modelo, uma única API, para executar várias tarefas diferentes, em vez de precisar treinar e implantar diversos modelos diferentes.

Com isso, vamos direto ao código para ver como aproveitar esse recurso. Aqui está o nosso código inicial de sempre. Vou apenas executá-lo.

O exemplo mais apropriado que vou usar é uma avaliação de uma luminária. Algo como: “Precisava de uma luminária bonita para o quarto e essa tem espaço extra de armazenamento”, e por aí vai.

Então, vou escrever um prompt para classificar o sentimento dessa avaliação. Se eu quiser que o sistema me diga, por exemplo, qual é o sentimento expressado...

Posso simplesmente escrever: “Qual é o sentimento da seguinte avaliação de produto?”, com o delimitador padrão e o texto da avaliação, e então executar.

O resultado é: “O sentimento da avaliação do produto é positivo.” O que, de fato, parece certo. Essa luminária não é perfeita, mas o cliente parece bem satisfeito. Parece ser uma ótima empresa que se importa com os clientes e com seus produtos. Acho que “sentimento positivo” é uma resposta adequada.

Agora, isso imprime a frase completa: “O sentimento da avaliação do produto é positivo.”

Se você quiser uma resposta mais concisa para facilitar o pós-processamento, pode pegar esse prompt e adicionar uma instrução pedindo uma resposta de uma só palavra — “positivo” ou “negativo”. Assim, ele imprime apenas “positivo”, o que facilita para um sistema automatizado receber esse resultado e fazer algo com ele.

Vamos ver outro prompt, ainda usando a mesma avaliação da luminária.

Aqui está: “Identifique uma lista de emoções que o autor da seguinte avaliação está expressando. Inclua no máximo cinco itens nessa lista.”

Modelos de linguagem de larga escala são muito bons em extrair informações específicas de um texto. Neste caso, estamos expressando emoções, o que pode ser útil para entender como seus clientes pensam sobre um determinado produto.

Para muitas equipes de suporte ao cliente, é importante saber se um usuário está extremamente insatisfeito. Você pode ter um problema de classificação diferente, como: “O autor da seguinte avaliação está expressando raiva?”. Porque se alguém estiver realmente bravo, pode valer a pena dar atenção especial àquela avaliação — com a equipe de suporte ou sucesso do cliente entrando em contato para entender o problema e resolver a situação.

Neste exemplo, o cliente não está com raiva. E repare que, com aprendizado supervisionado, se eu quisesse construir todos esses classificadores, não teria conseguido fazer isso em apenas alguns minutos, como mostrei neste vídeo.

Te encorajo a pausar o vídeo e testar modificações nesses prompts. Tente perguntar se o cliente está expressando alegria, ou se há alguma parte faltando, e veja se consegue criar um prompt que gere inferências diferentes sobre essa avaliação da luminária.

Vou mostrar mais possibilidades que você pode explorar com esse sistema, especialmente relacionadas à extração de informações mais detalhadas de uma avaliação.

A extração de informações é uma parte da PLN (Processamento de Linguagem Natural) que lida com pegar um texto e extrair dados específicos que você quer saber. Neste prompt, por exemplo, estou pedindo para identificar os seguintes itens: o produto comprado e o nome da empresa que fabricou esse produto.

Se você estiver resumindo várias avaliações de um site de e-commerce, pode ser útil descobrir quais foram os itens comprados, quem os fabricou, analisar sentimentos positivos ou negativos e acompanhar tendências de sentimento relacionadas a produtos ou fabricantes específicos.

Neste exemplo, peço para formatar a resposta como um objeto JSON com “Item” e “Marca” como chaves. E o resultado diz que o item é uma luminária e a marca é Lumina. Dá para carregar isso facilmente em um dicionário Python e fazer processamento adicional com essa saída.

Nos exemplos anteriores, vimos como escrever prompts para identificar sentimento, verificar se alguém está com raiva, e também extrair o item e a marca.

Uma forma de extrair todas essas informações seria usar três ou quatro prompts e chamar a função get_completion três ou quatro vezes, uma para cada informação. Mas na verdade, dá para escrever um único prompt que extrai tudo ao mesmo tempo.

Então podemos escrever: “Identifique os seguintes dados: sentimento, se o autor expressa raiva, item comprado, empresa que o fabricou”. E eu ainda digo para formatar o valor referente à raiva como um booleano.

O retorno é um JSON onde o sentimento é positivo, a raiva é false (sem aspas, já que pedimos um valor booleano), o item é “luminária com compartimento extra” — em vez de apenas “luminária”, o que está ok.

Assim, é possível extrair vários campos de um texto com um único prompt.

Como sempre, sinta-se à vontade para pausar o vídeo e testar diferentes variações.

Ou tente digitar uma avaliação totalmente diferente para ver se consegue extrair essas informações com precisão.

Agora, uma das aplicações mais interessantes que já vi de modelos de linguagem é a inferência de tópicos. Dado um texto longo, o que ele aborda? Quais são os assuntos? Aqui temos um artigo fictício de jornal sobre como funcionários públicos se sentem sobre os órgãos em que trabalham.

A pesquisa recente conduzida pelo governo, e por aí vai. “Os resultados revelaram que a NASA foi um dos departamentos mais populares, com alta taxa de satisfação.” Sou fã da NASA, adoro o trabalho que eles fazem — mas este artigo é fictício.

Diante de um texto como esse, podemos usar um prompt para determinar cinco tópicos que estão sendo discutidos no artigo.

Vamos fazer com que cada item tenha uma ou duas palavras, e que a resposta seja uma lista separada por vírgulas. Ao executar, temos o seguinte: este artigo trata de uma pesquisa governamental, fala sobre satisfação no trabalho, sobre a NASA, entre outros temas. No geral, acho que foi uma extração bem feita da lista de tópicos. E, claro, você também pode dividir isso e obter uma lista Python com os cinco tópicos abordados no artigo.

Se você tiver uma coleção de artigos e extrair os tópicos, também pode usar um modelo de linguagem para ajudá-lo a indexar esses conteúdos por temas. Vamos usar uma lista de tópicos um pouco diferente: digamos que somos um site de notícias e esses são os tópicos que monitoramos — “NASA, governo local, engenharia, satisfação dos funcionários, governo federal”.

Digamos que você queira descobrir, com base em um artigo, quais desses tópicos são abordados.

Aqui está um prompt que posso usar: "Determine se cada item na lista final de tópicos é mencionado no texto abaixo. Dê sua resposta como uma lista de 0 ou 1 para cada tópico."

E ótimo! Este é o mesmo texto do artigo anterior. O conteúdo é uma matéria sobre a NASA. Não trata de governo local. Não trata de engenharia. Fala sobre satisfação dos funcionários e também sobre o governo federal. No aprendizado de máquina, isso é chamado de algoritmo de aprendizado "zero-shot", porque não fornecemos nenhum conjunto de dados rotulados — e ainda assim, só com o prompt, conseguimos descobrir quais tópicos estão presentes no artigo.

Então, se quiser criar um sistema de alerta de notícias que processe artigos — e eu realmente gosto muito do trabalho da NASA — você pode montar um sistema que pegue essa informação, coloque num dicionário, e toda vez que surgir uma matéria sobre a NASA, imprimir: "ALERTA: nova matéria sobre a NASA!"

Ah, só um detalhe: eu usei esse dicionário de tópicos aqui embaixo. Esse prompt que usei mais acima não é muito robusto. Se fosse para usar em produção, eu provavelmente pediria que ele gerasse a resposta em formato JSON em vez de uma lista, porque os modelos de linguagem podem produzir saídas inconsistentes. Então, esse é um código meio frágil.

Mas, se quiser, quando terminar de assistir ao vídeo, sinta-se livre para tentar modificar esse prompt para que ele gere um JSON e tenha uma forma mais confiável de saber se um determinado artigo é uma matéria sobre a NASA.

Então, é isso sobre inferência. E em apenas alguns minutos, é possível construir diversos sistemas para fazer inferências sobre texto — algo que antes levaria dias ou até semanas para um desenvolvedor experiente em aprendizado de máquina.

Acho muito empolgante que, tanto para especialistas quanto para iniciantes, agora é possível usar prompts e rapidamente começar a aplicar inferências em tarefas bem complexas de processamento de linguagem natural.

No próximo vídeo, continuaremos explorando coisas incríveis que podemos fazer com modelos de linguagem, e vamos falar sobre “Transformação”: como pegar um texto e transformá-lo em outro, como traduzir para outra língua. Vamos seguir adiante!
